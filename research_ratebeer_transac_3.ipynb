{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data walking through"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transac = pd.read_csv(\"dataset/ratebeer/transac.csv\", header=None)\n",
    "columns = [\"GiverID\", \"ReceiverID\", \"itemID\", \"timestamp\"]\n",
    "transac.columns = columns\n",
    "transac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_row = len(transac)\n",
    "# get number of products\n",
    "number_of_product = len(np.unique(transac[\"itemID\"]))\n",
    "\n",
    "transac_grouped = transac.groupby([\"GiverID\", \"ReceiverID\", \"timestamp\"]).aggregate(lambda x: list(np.unique(x)))\n",
    "number_of_transac = len(transac_grouped)\n",
    "\n",
    "transac_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_index = [i for i in range(len(transac_grouped))]\n",
    "transac_grouped.index = _index\n",
    "transac_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of row:\", number_of_row)\n",
    "print(\"Number of product:\", number_of_product)\n",
    "print(\"Number of transac:\", number_of_transac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transactionEncoder(df):\n",
    "    # 'transactions' is now temporary variable\n",
    "    transactions = [row[\"itemID\"] for index, row in df.iterrows()]\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "    transaction_encoder = TransactionEncoder()\n",
    "    transac_matrix = transaction_encoder.fit_transform(transactions).astype(\"int\")\n",
    "    transac_df = pd.DataFrame(transac_matrix, columns=transaction_encoder.columns_)\n",
    "\n",
    "    return transac_df, transac_matrix"
   ]
  },
  {
   "source": [
    "# Transaction-based wish prediction using apriori"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "transac_df, transac_matrix = transactionEncoder(transac_grouped)\n",
    "\n",
    "frequent_itemsets = apriori(transac_df, min_support=0.2)\n",
    "print(frequent_itemsets)\n",
    "# rules = association_rules(frequent_itemsets, metric=\"confidence\")\n",
    "# # Something FAILED\n",
    "# rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(transac_df.sum(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_col, rmap_col = {}, {}\n",
    "idx, _columns = 0, []\n",
    "for val in transac_df.columns:\n",
    "    map_col[val] = idx\n",
    "    rmap_col[idx] = val\n",
    "    _columns.append(idx)\n",
    "    idx += 1"
   ]
  },
  {
   "source": [
    "# User-based prediction using cosine similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "t = cosine_similarity(transac_df[1:2], transac_matrix[:])[0]\n",
    "\n",
    "mx = 0\n",
    "for i in t:\n",
    "    if i < 1 and i > mx:\n",
    "        mx = i\n",
    "        print(i)\n",
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(len(t)):\n",
    "    arr.append((t[i], i))\n",
    "\n",
    "arr = sorted(arr)[::-1]\n",
    "arr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_row_df(items, _columns):\n",
    "    row_df = pd.DataFrame(data=[np.zeros(len(_columns)).astype(int)], columns=_columns)\n",
    "    for i in items:\n",
    "        row_df[i] = 1\n",
    "    return row_df\n",
    "\n",
    "def predict (utility_df, utility_matrix, return_num=5):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    for i in range(len(utility_matrix)):\n",
    "        sim = cosine_similarity(utility_df, utility_matrix[i:i+1])[0][0]\n",
    "        if 0. < sim and sim < 1.:\n",
    "            return transac_grouped.iloc[i][0]\n",
    "    return []\n",
    "    # sim_items = cosine_similarity(utility_df, utility_matrix[:200])[0]\n",
    "    # result = []\n",
    "    # for i in range(len(sim_items)):\n",
    "    #     if 0.5 < sim_items[i] and sim_items[i] < 1.:\n",
    "    #         return transac_grouped.iloc[i][0]\n",
    "    #         result.append((sim_items[i], transac_grouped.iloc[i][0]))\n",
    "    # result = sorted(result)[::-1][:return_num]\n",
    "    # print(time.time()-start_time)\n",
    "    # return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = int(0.7*len(transac_grouped))\n",
    "# print(pivot)\n",
    "train_set = transac_grouped[:pivot]\n",
    "test_set  = transac_grouped[pivot:]\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def in_train_lst(lst, _columns):\n",
    "    for i in lst:\n",
    "        if i not in _columns:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def givenN_evaluate(train, test, given_num):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    train_df, train_matrix = transactionEncoder(train)\n",
    "\n",
    "    score = cnt = 0\n",
    "    for i in range(len(test)):\n",
    "        lst = test.iloc[i][0]\n",
    "        \n",
    "        if len(lst) <= given_num or not in_train_lst(lst, train_df.columns):\n",
    "            continue\n",
    "        given_items = lst[:-given_num]\n",
    "        test_items = lst[-given_num:]\n",
    "        row_df = to_row_df(test_items, train_df.columns)\n",
    "        suggests = predict(row_df, train_matrix)\n",
    "        print(\"{}/{} {} - {}\".format(cnt+1, i+1, lst[given_num:], suggests))\n",
    "        if len(suggests):\n",
    "            for s in suggests:\n",
    "                if s in test_items:\n",
    "                    score += 1\n",
    "                    break\n",
    "        cnt += 1\n",
    "        # if cnt == 200:\n",
    "        #     break\n",
    "    print(time.time() - start_time)\n",
    "    print('cnt=', cnt)\n",
    "    return score\n",
    "\n",
    "score = givenN_evaluate(train_set, test_set, 1) #given 1\n",
    "score"
   ]
  }
 ]
}