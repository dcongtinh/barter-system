{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data walking through"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                  productId\npersonId                                                   \n39        [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n63                                    [36407, 36624, 53647]\n69        [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n154       [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n181       [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                     ...\n350591    [7502, 32329, 77319, 175070, 183623, 224747, 2...\n364565     [127129, 143745, 198143, 240704, 251402, 300610]\n367177        [902, 150716, 250972, 270373, 326021, 391163]\n367429                                             [159486]\n371199    [56242, 71868, 114487, 122097, 131539, 141185,...\n\n[1953 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# read csv and assign columns\n",
    "columns = [\"personId\", \"productId\"]\n",
    "df = pd.read_csv(\"dataset/ratebeer/wish.csv\", header=None)\n",
    "df.columns = columns\n",
    "\n",
    "number_of_row = len(df)\n",
    "# get number of products\n",
    "number_of_product = len(np.unique(df[\"productId\"]))\n",
    "# get number of person\n",
    "number_of_person = len(np.unique(df[\"personId\"]))\n",
    "df = df.groupby(\"personId\").aggregate(lambda x: list(np.unique(x)))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                  productId\npersonId                                                   \n39                                                 [102296]\n69                               [1195, 5923, 31915, 37101]\n154       [2487, 2490, 7223, 18573, 22427, 24021, 32152,...\n189       [1924, 1949, 2210, 3013, 3014, 3015, 3062, 306...\n605                   [164, 371, 5400, 22905, 30812, 30896]\n...                                                     ...\n367177    [1090, 1156, 1671, 1676, 1677, 4584, 6004, 373...\n367429      [15917, 113329, 141718, 156177, 168309, 329901]\n367573                   [8936, 38052, 43947, 48429, 94349]\n371199                                             [173262]\n375283    [4430, 4934, 6014, 6034, 6074, 6075, 6924, 692...\n\n[1806 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = [\"personId\", \"productId\"]\n",
    "have_df = pd.read_csv(\"dataset/ratebeer/have.csv\", header=None)\n",
    "have_df.columns = columns\n",
    "have_df = have_df.groupby(\"personId\").aggregate(lambda x: list(np.unique(x)))\n",
    "print(have_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                  productId\npersonId                                                   \n39        [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n63                                    [36407, 36624, 53647]\n69        [1195, 2442, 2491, 3401, 5923, 6924, 9193, 137...\n154       [565, 1432, 2487, 2490, 3213, 7223, 7686, 1069...\n181       [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                     ...\n361285    [16, 421, 429, 531, 2404, 2526, 4315, 4503, 46...\n364066    [17557, 22904, 30838, 40544, 42344, 68107, 996...\n365722                                        [8936, 48429]\n367573                   [8936, 38052, 43947, 48429, 94349]\n375283    [4430, 4934, 6014, 6034, 6074, 6075, 6924, 692...\n\n[2215 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "_df = df\n",
    "cnt = 0\n",
    "for i in range(len(have_df)):\n",
    "    have_PID = have_df.iloc[i].name\n",
    "    if have_PID in _df.index.values:\n",
    "        _df.loc[have_PID][0] = np.append(_df.loc[have_PID][0], have_df.iloc[i][0])\n",
    "        _df.loc[have_PID][0] = np.unique(_df.loc[have_PID][0])\n",
    "    else:\n",
    "        _df = _df.append(have_df.iloc[i])\n",
    "print(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(_df)):\n",
    "    _df.iloc[i][0] = str(list(_df.iloc[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                  productId\npersonId                                                   \n39        [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n63                                    [36407, 36624, 53647]\n69        [1195, 2442, 2491, 3401, 5923, 6924, 9193, 137...\n154       [565, 1432, 2487, 2490, 3213, 7223, 7686, 1069...\n181       [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                     ...\n361285    [16, 421, 429, 531, 2404, 2526, 4315, 4503, 46...\n364066    [17557, 22904, 30838, 40544, 42344, 68107, 996...\n365722                                        [8936, 48429]\n367573                   [8936, 38052, 43947, 48429, 94349]\n375283    [4430, 4934, 6014, 6034, 6074, 6075, 6924, 692...\n\n[2210 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "_df = _df.drop_duplicates()\n",
    "print(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n1                                 [36407, 36624, 53647]\n2     [1195, 2442, 2491, 3401, 5923, 6924, 9193, 137...\n3     [565, 1432, 2487, 2490, 3213, 7223, 7686, 1069...\n4     [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                 ...\n2205  [16, 421, 429, 531, 2404, 2526, 4315, 4503, 46...\n2206  [17557, 22904, 30838, 40544, 42344, 68107, 996...\n2207                                      [8936, 48429]\n2208                 [8936, 38052, 43947, 48429, 94349]\n2209  [4430, 4934, 6014, 6034, 6074, 6075, 6924, 692...\n\n[2210 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "_index = [i for i in range(len(_df))]\n",
    "_df.index = _index\n",
    "print(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n1                                 [36407, 36624, 53647]\n2     [1195, 2442, 2491, 3401, 5923, 6924, 9193, 137...\n3     [565, 1432, 2487, 2490, 3213, 7223, 7686, 1069...\n4     [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                 ...\n2205  [16, 421, 429, 531, 2404, 2526, 4315, 4503, 46...\n2206  [17557, 22904, 30838, 40544, 42344, 68107, 996...\n2207                                      [8936, 48429]\n2208                 [8936, 38052, 43947, 48429, 94349]\n2209  [4430, 4934, 6014, 6034, 6074, 6075, 6924, 692...\n\n[2210 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(_df)):\n",
    "    _df.iloc[i][0] = list(eval(_df.iloc[i][0]))\n",
    "print(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[     1      2      3 ... 394150 394158 395581]\n"
     ]
    }
   ],
   "source": [
    "item_values = np.array([])\n",
    "for i in range(len(_df)):\n",
    "    item_values = np.hstack((item_values, _df.iloc[i][0]))\n",
    "item_values = np.unique(item_values).astype(int)\n",
    "print(item_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_col, rmap_col = {}, {}\n",
    "idx, _columns = 0, []\n",
    "for val in item_values:\n",
    "    map_col[val] = idx\n",
    "    rmap_col[idx] = val\n",
    "    _columns.append(idx)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [203, 251, 350, 352, 353, 494, 560, 635, 735, ...\n1                                    [5666, 5671, 7176]\n2     [509, 864, 884, 1106, 1641, 1896, 2454, 3272, ...\n3     [253, 590, 880, 883, 1067, 1990, 2119, 2742, 3...\n4     [1234, 1982, 2188, 2692, 2810, 3327, 4015, 426...\n...                                                 ...\n2205  [10, 180, 188, 228, 844, 917, 1260, 1301, 1353...\n2206  [3779, 4316, 5168, 6033, 6181, 8534, 11764, 11...\n2207                                       [2393, 6698]\n2208                    [2393, 5794, 6323, 6698, 11148]\n2209  [1278, 1429, 1691, 1697, 1709, 1710, 1896, 189...\n\n[2210 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(_df)):\n",
    "    _df.iloc[i][0] = [map_col[val] for val in _df.iloc[i][0]]\n",
    "print(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transactionEncoder(df):\n",
    "    # 'transactions' is now temporary variable\n",
    "    transactions = [row[\"productId\"] for index, row in df.iterrows()]\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "    transaction_encoder = TransactionEncoder()\n",
    "    wish_matrix = transaction_encoder.fit_transform(transactions).astype(\"int\")\n",
    "    wish_df = pd.DataFrame(wish_matrix, columns=transaction_encoder.columns_)\n",
    "\n",
    "    return wish_df, wish_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   0      1      2      3      4      5      6      7      8      9      ...  \\\n0      0      0      0      0      0      0      0      0      0      0  ...   \n1      0      0      0      0      0      0      0      0      0      0  ...   \n2      0      0      0      0      0      0      0      0      0      0  ...   \n3      0      0      0      0      0      0      0      0      0      0  ...   \n4      0      0      0      0      0      0      0      0      0      0  ...   \n\n   26562  26563  26564  26565  26566  26567  26568  26569  26570  26571  \n0      0      0      0      0      0      0      0      0      0      0  \n1      0      0      0      0      0      0      0      0      0      0  \n2      0      0      0      0      0      0      0      0      0      0  \n3      0      0      0      0      0      0      0      0      0      0  \n4      0      0      0      0      0      0      0      0      0      0  \n\n[5 rows x 26572 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "wish_df, wish_matrix = transactionEncoder(_df)\n",
    "\n",
    "print(wish_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n       118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n       133, 134, 135, 136, 137, 140, 141, 142, 143, 145, 149, 151, 152,\n       153, 154, 155, 158, 159, 161, 162, 163, 165, 166, 167, 168, 169,\n       170, 171, 177, 180, 181, 182, 183, 184, 185, 187, 189, 190, 192,\n       194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208,\n       209, 210, 211, 212, 218, 220, 223, 228, 229, 231, 234, 239, 245,\n       247, 248, 250, 252, 254, 255, 257, 259, 264, 268, 269, 271, 277,\n       282, 283, 284, 299, 307, 310, 315, 316, 357, 360, 368, 388, 391,\n       396, 415, 426, 431, 449, 482, 483, 600]), array([12821,  4031,  2023,  1296,   882,   712,   517,   417,   332,\n         315,   241,   234,   188,   157,   132,   138,   115,   112,\n          90,    86,    73,    79,    69,    60,    54,    37,    55,\n          39,    44,    32,    42,    32,    41,    37,    29,    28,\n          43,    21,    37,    21,    17,    36,    19,    20,    15,\n          22,    17,    18,    16,    25,    12,    20,    16,    13,\n          11,    26,    11,    16,    15,    14,    10,    20,     9,\n          13,     6,     7,     8,     7,    12,     2,     6,     7,\n           6,     9,     4,     7,     7,     4,     2,    12,     8,\n           7,     6,     5,     9,     3,     4,     7,     2,     3,\n           1,     8,     4,     9,     7,     4,     5,     4,     5,\n           2,     5,     1,     2,     4,     6,     5,     1,     3,\n           3,     2,     3,     1,     5,     3,     3,     5,     1,\n           4,     2,     5,     4,     2,     4,     6,     2,     3,\n           1,     3,     2,     1,     1,     1,     4,     2,     5,\n           1,     2,     1,     2,     1,     1,     3,     1,     2,\n           1,     3,     2,     3,     3,     3,     2,     2,     2,\n           2,     2,     2,     1,     1,     1,     1,     1,     2,\n           3,     2,     1,     2,     2,     1,     1,     1,     1,\n           3,     2,     1,     1,     4,     1,     1,     1,     1,\n           1,     1,     1,     1,     1,     2,     1,     1,     1,\n           1,     1,     1,     1,     1,     3,     1,     1,     3,\n           1,     2,     1,     1,     1,     1,     1,     1,     1,\n           1,     1,     3,     1,     1,     1,     1,     1,     1,\n           1,     2,     1,     1,     1,     1,     1,     1,     1,\n           1,     1,     1,     1]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(wish_df.sum(), return_counts=True))"
   ]
  },
  {
   "source": [
    "# Transaction-based wish prediction using apriori"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    support itemsets\n0  0.203167   (1429)\n1  0.218100   (2388)\n2  0.271493   (3566)\n3  0.218552   (8223)\nEmpty DataFrame\nColumns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "frequent_itemsets = apriori(wish_df, min_support=0.2)\n",
    "print(frequent_itemsets)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\")\n",
    "# Something FAILED\n",
    "print(rules)"
   ]
  },
  {
   "source": [
    "# User-based prediction using cosine similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def to_row_df(items, _columns):\n",
    "    row_df = pd.DataFrame(data=[np.zeros(len(_columns)).astype(int)], columns=_columns)\n",
    "    for i in items:\n",
    "        row_df[i] = 1\n",
    "    return row_df\n",
    "\n",
    "def predict (utility_df, utility_matrix, test_items, return_num=5):\n",
    "    sim_items = cosine_similarity(utility_df, utility_matrix[:])[0]\n",
    "    \n",
    "    for j in test_items:\n",
    "        tu = mau = 0\n",
    "        for i in range(utility_matrix.shape[0]):\n",
    "            tu += sim_items[i] * utility_matrix[i][j]\n",
    "            mau += sim_items[i]\n",
    "        pred = tu/mau\n",
    "        if pred > 0:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1547\n663\n"
     ]
    }
   ],
   "source": [
    "pivot = int(0.7*len(_df))\n",
    "# print(pivot)\n",
    "train_set = _df[:pivot]\n",
    "test_set  = _df[pivot:]\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_train_lst(lst, _columns):\n",
    "    for i in lst:\n",
    "        if i not in _columns or i > len(_columns):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def givenN_evaluate(train, test, given_num):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    train_df, train_matrix = transactionEncoder(train)\n",
    "    score = cnt = 0\n",
    "    for i in range(len(test)):\n",
    "        lst = test.iloc[i][0]\n",
    "        if len(lst) <= given_num or not in_train_lst(lst, train_df.columns):\n",
    "            continue\n",
    "        given_items = lst[:-given_num]\n",
    "        test_items = lst[-given_num:]\n",
    "        row_df = to_row_df(test_items, train_df.columns)\n",
    "        _start_time = time.time()\n",
    "        score += predict(row_df, train_matrix, test_items, 10)\n",
    "        cnt += 1\n",
    "        print(\"{}/{} - score = {} - time = {}\".format(cnt, i+1, score, time.time() - _start_time))\n",
    "        # if cnt == 10:\n",
    "        #     break\n",
    "    print(time.time() - start_time)\n",
    "    print('cnt =', cnt)\n",
    "    return score\n",
    "\n",
    "score = givenN_evaluate(train_set, test_set, 1) #given 1\n",
    "print('score =', score)"
   ]
  }
 ]
}