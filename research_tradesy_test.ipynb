{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd09ddfba760c93d0781cb88c4db9a31eb68ca4e1616821530f19d735f356a5c9ec",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "9ddfba760c93d0781cb88c4db9a31eb68ca4e1616821530f19d735f356a5c9ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import data from json"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"dataset/tradesy.json\", \"r\") as f:\n",
    "    user_transactions = json.loads(f.read())"
   ]
  },
  {
   "source": [
    "# Stat:\n",
    "- See how many products\n",
    "- Which fields, and which should be concerned"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'uid': '1',\n",
       "  'lists': {'sold': ['3', '2'], 'selling': [], 'want': [], 'bought': []}},\n",
       " {'uid': '2',\n",
       "  'lists': {'sold': ['104', '103', '102'],\n",
       "   'selling': [],\n",
       "   'want': [],\n",
       "   'bought': ['466', '459', '457', '449']}},\n",
       " {'uid': '3',\n",
       "  'lists': {'sold': ['845', '833', '829'],\n",
       "   'selling': [],\n",
       "   'want': [],\n",
       "   'bought': ['874',\n",
       "    '861',\n",
       "    '860',\n",
       "    '857',\n",
       "    '852',\n",
       "    '850',\n",
       "    '847',\n",
       "    '842',\n",
       "    '160',\n",
       "    '143',\n",
       "    '142',\n",
       "    '141',\n",
       "    '140',\n",
       "    '139',\n",
       "    '93',\n",
       "    '88',\n",
       "    '87',\n",
       "    '84',\n",
       "    '81',\n",
       "    '70',\n",
       "    '66',\n",
       "    '63',\n",
       "    '61',\n",
       "    '60']}}]"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "user_transactions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of users: 128152\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of users:\", len(user_transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fields of each user records: uid, lists\nFields of each tx lists: sold, selling, want, bought\n"
     ]
    }
   ],
   "source": [
    "print(\"Fields of each user records:\", \", \".join(user_transactions[0].keys()))\n",
    "print(\"Fields of each tx lists:\", \", \".join(user_transactions[0][\"lists\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique items: 227856\n=> Size to store: ~ 27847.482788085938 MB, > 8 GB RAM\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_unique_items(user_transactions):\n",
    "    item_ids = []\n",
    "    for tx in user_transactions:\n",
    "        if not len(tx[\"lists\"][\"want\"]):\n",
    "            continue\n",
    "        item_ids.extend(tx[\"lists\"][\"want\"])\n",
    "        item_ids.extend(tx[\"lists\"][\"selling\"])\n",
    "    unique_ids = np.unique(item_ids, return_counts=True)\n",
    "    return unique_ids\n",
    "\n",
    "unique_ids, counts = get_unique_items(user_transactions)\n",
    "print(\"Unique items:\", len(unique_ids))\n",
    "print(\"=> Size to store: ~\", len(unique_ids) * len(user_transactions) / 1024 / 1024, \"MB, > 8 GB RAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1000001' '1000003' '1000007' ... '999991' '999992' '999998']\n"
     ]
    }
   ],
   "source": [
    "print(unique_ids)"
   ]
  },
  {
   "source": [
    "# Recommender system focus on \"sold\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data: transaction jsons => table\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder \n",
    "\n",
    "userToSold = {}\n",
    "focus_transactions = user_transactions\n",
    "sold_list = []\n",
    "for tx in focus_transactions:\n",
    "    if len(tx[\"lists\"][\"sold\"]) == 0:\n",
    "        continue \n",
    "    userToSold[tx[\"uid\"]] = list(map(int, tx[\"lists\"][\"sold\"]))\n",
    "    userToSold[tx[\"uid\"]] = list(map(int, tx[\"lists\"][\"bought\"]))\n",
    "    sold_list.append(userToSold[tx[\"uid\"]])\n",
    "\n",
    "# encoder = TransactionEncoder()\n",
    "# sold_list_matrix = encoder.fit_transform(sold_list).astype(\"int\")\n",
    "\n",
    "# df = pd.DataFrame(sold_list_matrix, columns=encoder.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17489\n"
     ]
    }
   ],
   "source": [
    "print(len(sold_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Empty DataFrame\nColumns: [support, itemsets]\nIndex: []\nNumber of rules: 0\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "fq_itemset = apriori(df, min_support=0.1, use_colnames=True)\n",
    "\n",
    "print(fq_itemset)\n",
    "print(\"Number of rules:\", len(fq_itemset))\n",
    "# rules = association_rules(fq_itemset, metric='lift')\n",
    "# print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]]\n7735\nInt64Index([682, 767, 814, 810, 807], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "new_item = df[56]\n",
    "# print(new_item)\n",
    "sim = cosine_similarity([new_item], df.T)\n",
    "print(sim)\n",
    "print(len(sim[0]))\n",
    "sim = pd.Series(sim[0], index=df.columns)\n",
    "sim_sorted = sim.sort_values(ascending=False)[:5]\n",
    "print(sim_sorted.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (item, utility_matrix):\n",
    "    sim_items = cosine_similarity([item], utility_matrix.T)\n",
    "    sim_items = pd.Series(sim_items[0], index=utility_matrix.columns)\n",
    "    recommend = sim_items.sort_values(ascending=False)\n",
    "    result = []\n",
    "    for item, cosine in recommend.iteritems():\n",
    "        if cosine > 0:\n",
    "            result.append(item)\n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17489\n",
      "3355\n",
      "2348\n",
      "1007\n",
      "\n",
      "userid 683106: [683106, 1453593, 1453585, 1108462, 829993, 707030]\n",
      "--------->recommend from[683106]: {745952, 683106, 141317, 1343720, 778089, 40458, 774317, 390640, 779506, 899258, 731357, 164511}\n",
      "\n",
      "userid 698251: [698251, 407686]\n",
      "--------->recommend from[698251]: {785289, 261514, 698251, 808719, 334752, 1249185, 398882, 769828, 265388, 345905, 181044, 809019, 747330, 254153, 114250, 412495, 1456088, 118108, 890214, 125031, 735846, 751863, 405246}\n",
      "\n",
      "userid 1354852: [1354852, 1465949, 1314702, 1235765, 1228222, 1227904, 1215486, 1213877, 1180868, 1179223, 1179161, 1080923, 1049035, 695855]\n",
      "--------->recommend from[1354852]: {1013760, 1195396, 1462661, 1442950, 1533067, 1462033, 1507226, 1206300, 1453728, 1274017, 1462051, 1527209, 1398314, 1473963, 1241902, 1378992, 1371824, 1444538, 855101, 1517374, 1476160, 1163358, 1378916, 1354852, 1465958, 1268585, 513771, 1167214, 1465972, 1195384, 1287931, 1556860}\n",
      "\n",
      "userid 395086: [395086, 1426677, 1210001, 1179898, 1145309, 1114339, 1071627, 347051]\n",
      "--------->recommend from[395086]: {705123, 395086}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(sold_list))\n",
    "new = []\n",
    "for s in sold_list:\n",
    "    if s:\n",
    "        new.append(s)\n",
    "print(len(new))\n",
    "\n",
    "pivot = int(0.7*len(new))\n",
    "# print(pivot)\n",
    "train_set = new[:pivot]\n",
    "test_set  = new[pivot:]\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "\n",
    "def givenN_evaluate(train, test, given_num):\n",
    "    encoder = TransactionEncoder()\n",
    "    utility_matrix = encoder.fit_transform(train)\n",
    "    utility_matrix = pd.DataFrame(utility_matrix, columns=encoder.columns_).astype(int)\n",
    "    # print(utility_matrix.shape)\n",
    "    # print(utility_matrix.columns)\n",
    "    # print(utility_matrix)\n",
    "    score = 0\n",
    "    for i, t in enumerate(test):\n",
    "        if len(t) <= given_num: continue \n",
    "        items = t[:given_num]\n",
    "        # print(items)\n",
    "        suggests = set()\n",
    "        for i in items:\n",
    "            if i not in utility_matrix.columns: continue\n",
    "            suggests.update(predict(utility_matrix[i], utility_matrix))\n",
    "        \n",
    "        if suggests:  \n",
    "            print('\\nuser {}: {}'.format(i, t))  \n",
    "            print('--------->recommend from{}: {}'.format(items, suggests))\n",
    "    \n",
    "        for s in suggests:\n",
    "            if s in t[given_num:]: score += 1\n",
    "\n",
    "    return score\n",
    "\n",
    "score = givenN_evaluate(train_set, test_set, 1) #given 1\n",
    "print(score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}