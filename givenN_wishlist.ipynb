{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data walking through"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# read csv and assign columns\n",
    "columns = [\"personId\", \"productId\"]\n",
    "df = pd.read_csv(\"dataset/ratebeer/wish.csv\", header=None)\n",
    "df.columns = columns\n",
    "\n",
    "number_of_row = len(df)\n",
    "# get number of products\n",
    "number_of_product = len(np.unique(df[\"productId\"]))\n",
    "# get number of person\n",
    "number_of_person = len(np.unique(df[\"personId\"]))\n",
    "df = df.groupby(\"personId\").aggregate(lambda x: str(list(np.unique(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of row: 118453\nNumber of person: 1953\nNumber of product: 21654\n                                                  productId\npersonId                                                   \n39        [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n63                                    [36407, 36624, 53647]\n69        [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n154       [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n181       [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of row:\", number_of_row)\n",
    "print(\"Number of person:\", number_of_person)\n",
    "print(\"Number of product:\", number_of_product)\n",
    "# first samples\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                  productId\npersonId                                                   \n39        [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n63                                    [36407, 36624, 53647]\n69        [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n154       [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n181       [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                     ...\n350591    [7502, 32329, 77319, 175070, 183623, 224747, 2...\n364565     [127129, 143745, 198143, 240704, 251402, 300610]\n367177        [902, 150716, 250972, 270373, 326021, 391163]\n367429                                             [159486]\n371199    [56242, 71868, 114487, 122097, 131539, 141185,...\n\n[1932 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n1                                 [36407, 36624, 53647]\n2     [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n3     [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n4     [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                 ...\n1927  [7502, 32329, 77319, 175070, 183623, 224747, 2...\n1928   [127129, 143745, 198143, 240704, 251402, 300610]\n1929      [902, 150716, 250972, 270373, 326021, 391163]\n1930                                           [159486]\n1931  [56242, 71868, 114487, 122097, 131539, 141185,...\n\n[1932 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "_index = [i for i in range(len(df))]\n",
    "df.index = _index\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n1                                 [36407, 36624, 53647]\n2     [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n3     [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n4     [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                 ...\n1927  [7502, 32329, 77319, 175070, 183623, 224747, 2...\n1928   [127129, 143745, 198143, 240704, 251402, 300610]\n1929      [902, 150716, 250972, 270373, 326021, 391163]\n1930                                           [159486]\n1931  [56242, 71868, 114487, 122097, 131539, 141185,...\n\n[1932 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    df.iloc[i][0] = list(eval(df.iloc[i][0]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[     1      2      3 ... 392402 392478 393042]\n"
     ]
    }
   ],
   "source": [
    "item_values = np.array([])\n",
    "for i in range(len(df)):\n",
    "    item_values = np.hstack((item_values, df.iloc[i][0]))\n",
    "item_values = np.unique(item_values).astype(int)\n",
    "print(item_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_col, rmap_col = {}, {}\n",
    "idx, _columns = 0, []\n",
    "for val in item_values:\n",
    "    map_col[val] = idx\n",
    "    rmap_col[idx] = val\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [146, 177, 252, 254, 255, 369, 428, 487, 567, ...\n1                                    [4696, 4700, 6038]\n2     [668, 686, 862, 1474, 1936, 2623, 2795, 3305, ...\n3     [179, 455, 830, 1660, 2179, 2704, 2795, 2961, ...\n4     [955, 1544, 1720, 2137, 2235, 2674, 3282, 3504...\n...                                                 ...\n1927  [1617, 4394, 8055, 16098, 16541, 18388, 18392,...\n1928         [12541, 13960, 17276, 18899, 19183, 20290]\n1929           [308, 14425, 19177, 19658, 20776, 21646]\n1930                                            [15047]\n1931  [6273, 7602, 11365, 12084, 12881, 13777, 15653...\n\n[1932 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    df.iloc[i][0] = [map_col[val] for val in df.iloc[i][0]]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transactionEncoder(df):\n",
    "    # 'transactions' is now temporary variable\n",
    "    transactions = [row[\"productId\"] for index, row in df.iterrows()]\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "    transaction_encoder = TransactionEncoder()\n",
    "    wish_matrix = transaction_encoder.fit_transform(transactions).astype(\"int\")\n",
    "    wish_df = pd.DataFrame(wish_matrix, columns=transaction_encoder.columns_)\n",
    "\n",
    "    return wish_df, wish_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   0      1      2      3      4      5      6      7      8      9      ...  \\\n0      0      0      0      0      0      0      0      0      0      0  ...   \n1      0      0      0      0      0      0      0      0      0      0  ...   \n2      0      0      0      0      0      0      0      0      0      0  ...   \n3      0      0      0      0      0      0      0      0      0      0  ...   \n4      0      0      0      0      0      0      0      0      0      0  ...   \n\n   21644  21645  21646  21647  21648  21649  21650  21651  21652  21653  \n0      0      0      0      0      0      0      0      0      0      0  \n1      0      0      0      0      0      0      0      0      0      0  \n2      0      0      0      0      0      0      0      0      0      0  \n3      0      0      0      0      0      0      0      0      0      0  \n4      0      0      0      0      0      0      0      0      0      0  \n\n[5 rows x 21654 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "wish_df, wish_matrix = transactionEncoder(df)\n",
    "\n",
    "print(wish_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  91,  92,\n        93,  94,  95,  96,  98,  99, 100, 102, 103, 104, 105, 106, 107,\n       109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n       122, 123, 124, 125, 126, 128, 131, 132, 134, 135, 136, 137, 140,\n       141, 142, 143, 144, 145, 146, 148, 149, 151, 153, 154, 158, 160,\n       161, 164, 165, 167, 169, 170, 172, 173, 174, 175, 178, 180, 183,\n       184, 185, 188, 189, 194, 197, 199, 202, 203, 205, 206, 210, 220,\n       228, 231, 232, 233, 240, 246, 248, 254, 299, 322, 347, 348, 356,\n       359, 374, 426]), array([10834,  3464,  1734,  1086,   728,   546,   409,   309,   269,\n         190,   166,   168,   148,   101,   107,    86,    77,    72,\n          51,    53,    57,    54,    38,    26,    38,    48,    28,\n          21,    28,    25,    26,    12,    19,    29,    21,    20,\n          18,    19,    15,    15,    21,    13,    16,     9,     8,\n          10,     9,    12,    10,     7,     8,     7,    12,    11,\n           9,     8,    15,     8,     6,     9,    10,     8,     7,\n           9,     8,     8,     4,     4,     5,     3,     3,     4,\n           2,     4,     5,     4,     6,     5,     2,     6,     3,\n           5,     5,     4,     4,     2,     3,     4,     3,     5,\n           5,     2,     1,     3,     1,     2,     1,     3,     1,\n           1,     1,     2,     3,     1,     1,     3,     3,     1,\n           3,     1,     3,     2,     2,     4,     2,     1,     2,\n           1,     1,     1,     1,     3,     1,     1,     1,     1,\n           1,     2,     2,     1,     1,     2,     2,     1,     2,\n           1,     2,     2,     2,     3,     1,     1,     1,     1,\n           1,     2,     1,     1,     1,     1,     1,     2,     1,\n           1,     2,     1,     2,     3,     1,     1,     1,     1,\n           2,     1,     1,     1,     1,     2,     1,     1,     1,\n           1,     1,     2,     1,     1,     3,     1,     1,     1,\n           1,     1,     1,     1,     1]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(wish_df.sum(), return_counts=True))"
   ]
  },
  {
   "source": [
    "# Transaction-based wish prediction using apriori"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    support itemsets\n0  0.166667   (2877)\n1  0.179607   (4032)\n2  0.185818   (5202)\n3  0.220497   (6441)\n4  0.154762   (6474)\n5  0.184265   (6965)\n6  0.180124   (7080)\n7  0.193582   (8021)\nEmpty DataFrame\nColumns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "frequent_itemsets = apriori(wish_df, min_support=0.15)\n",
    "print(frequent_itemsets)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\")\n",
    "# Something FAILED\n",
    "print(rules)"
   ]
  },
  {
   "source": [
    "# User-based prediction using cosine similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def to_row_df(items, _columns):\n",
    "    row_df = pd.DataFrame(data=[np.zeros(len(_columns)).astype(int)], columns=_columns)\n",
    "    for i in items:\n",
    "        row_df[i] = 1\n",
    "    return row_df\n",
    "\n",
    "def predict (given_items, row_df, train_df, test_items, return_num=5):\n",
    "    # print(train_df.iloc[:][given_items])\n",
    "    print(given_items)\n",
    "    \n",
    "    for j in range(len(train_df.columns)):\n",
    "        val = train_df.columns[j]\n",
    "        if val not in given_items:\n",
    "            if len(np.unique(train_df.iloc[:][val].values)) == 1:\n",
    "                given_items.append(val)\n",
    "    \n",
    "    dt1 = train_df.iloc[:][given_items]\n",
    "    row1_df = row_df.iloc[:][given_items]\n",
    "\n",
    "    # sim_items = cosine_similarity(row_df, train_df[:])[0]\n",
    "    # sim_items = train_df.corrwith(row_df, method='pearson')\n",
    "    # print(sim_items)\n",
    "    # return 0\n",
    "    for j in test_items:\n",
    "        tu = mau = 0\n",
    "        \n",
    "        corr_list = []\n",
    "        # print(train_df.shape[0])\n",
    "        for i in range(train_df.shape[0]):\n",
    "            # print(i, len(dt1.iloc[i]), len(row1_df.iloc[0]))\n",
    "            corr = pearsonr(dt1.iloc[i], row1_df.iloc[0])\n",
    "            corr_list.append(corr[0])\n",
    "\n",
    "        # print(corr_list)\n",
    "        return 1\n",
    "        \n",
    "        for i in range(train_df.shape[0]):\n",
    "            tu += sim_items[i] * (train_df.iloc[i][j] - np.mean(train_df.iloc[i].values))\n",
    "            mau += sim_items[i]\n",
    "        pred = np.mean(row_df.iloc[0].values) + tu/mau\n",
    "        # pred = tu/mau\n",
    "        print(pred)\n",
    "        if pred > 0.02:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1352\n580\n"
     ]
    }
   ],
   "source": [
    "pivot = int(0.7*len(df))\n",
    "# print(pivot)\n",
    "train_set = df[:pivot]\n",
    "test_set  = df[pivot:]\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1881, 2410, 2877, 4032, 5017, 5882, 6965, 8918, 10604, 10696, 11077, 11228, 11579]\n",
      "[2998]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "x and y must have length at least 2.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-3174166ce458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgivenN_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#given 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' | acc ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-3174166ce458>\u001b[0m in \u001b[0;36mgivenN_evaluate\u001b[0;34m(train, test, given_num)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrow_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_row_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiven_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0m_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiven_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print(\"{}/{} - score = {} - time = {}\".format(cnt, i+1, score, time.time() - _start_time))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-208df1df817b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(given_items, row_df, train_df, test_items, return_num)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# print(i, len(dt1.iloc[i]), len(row1_df.iloc[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow1_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mcorr_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   3499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3501\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x and y must have length at least 2.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "def in_train_lst(lst, _columns):\n",
    "    for i in lst:\n",
    "        if i not in _columns:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def givenN_evaluate(train, test, given_num):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    train_df, train_matrix = transactionEncoder(train)\n",
    "    score = cnt = 0\n",
    "    for i in range(len(test)):\n",
    "        lst = test.iloc[i][0]\n",
    "        if len(lst) <= given_num or not in_train_lst(lst, train_df.columns):\n",
    "            continue\n",
    "        given_items = lst[:-given_num]\n",
    "        test_items = lst[-given_num:]\n",
    "        row_df = to_row_df(given_items, train_df.columns)\n",
    "        _start_time = time.time()\n",
    "        score += predict(given_items, row_df, train_df, test_items, 10)\n",
    "        cnt += 1\n",
    "        # print(\"{}/{} - score = {} - time = {}\".format(cnt, i+1, score, time.time() - _start_time))\n",
    "        if cnt == 10:\n",
    "            break\n",
    "    print(time.time() - start_time)\n",
    "    print('cnt =', cnt)\n",
    "    return score, score/cnt\n",
    "\n",
    "score, acc = givenN_evaluate(train_set, test_set, 1) #given 1\n",
    "print('score =', score, ' | acc =', acc)"
   ]
  }
 ]
}