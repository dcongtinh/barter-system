{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data walking through"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# read csv and assign columns\n",
    "columns = [\"personId\", \"productId\"]\n",
    "df = pd.read_csv(\"dataset/ratebeer/wish.csv\", header=None)\n",
    "df.columns = columns\n",
    "\n",
    "number_of_row = len(df)\n",
    "# get number of products\n",
    "number_of_product = len(np.unique(df[\"productId\"]))\n",
    "# get number of person\n",
    "number_of_person = len(np.unique(df[\"personId\"]))\n",
    "df = df.groupby(\"personId\").aggregate(lambda x: str(list(np.unique(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of row: 118453\nNumber of person: 1953\nNumber of product: 21654\n                                                  productId\npersonId                                                   \n39        [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n63                                    [36407, 36624, 53647]\n69        [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n154       [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n181       [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of row:\", number_of_row)\n",
    "print(\"Number of person:\", number_of_person)\n",
    "print(\"Number of product:\", number_of_product)\n",
    "# first samples\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                  productId\npersonId                                                   \n39        [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n63                                    [36407, 36624, 53647]\n69        [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n154       [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n181       [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                     ...\n350591    [7502, 32329, 77319, 175070, 183623, 224747, 2...\n364565     [127129, 143745, 198143, 240704, 251402, 300610]\n367177        [902, 150716, 250972, 270373, 326021, 391163]\n367429                                             [159486]\n371199    [56242, 71868, 114487, 122097, 131539, 141185,...\n\n[1932 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n1                                 [36407, 36624, 53647]\n2     [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n3     [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n4     [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                 ...\n1927  [7502, 32329, 77319, 175070, 183623, 224747, 2...\n1928   [127129, 143745, 198143, 240704, 251402, 300610]\n1929      [902, 150716, 250972, 270373, 326021, 391163]\n1930                                           [159486]\n1931  [56242, 71868, 114487, 122097, 131539, 141185,...\n\n[1932 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "_index = [i for i in range(len(df))]\n",
    "df.index = _index\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [464, 562, 736, 739, 740, 1147, 1360, 1618, 21...\n1                                 [36407, 36624, 53647]\n2     [2442, 2491, 3401, 6924, 9193, 13730, 15017, 1...\n3     [565, 1432, 3213, 7686, 10691, 14286, 15017, 1...\n4     [4108, 7183, 7979, 10524, 11008, 14082, 19445,...\n...                                                 ...\n1927  [7502, 32329, 77319, 175070, 183623, 224747, 2...\n1928   [127129, 143745, 198143, 240704, 251402, 300610]\n1929      [902, 150716, 250972, 270373, 326021, 391163]\n1930                                           [159486]\n1931  [56242, 71868, 114487, 122097, 131539, 141185,...\n\n[1932 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    df.iloc[i][0] = list(eval(df.iloc[i][0]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[     1      2      3 ... 392402 392478 393042]\n"
     ]
    }
   ],
   "source": [
    "item_values = np.array([])\n",
    "for i in range(len(df)):\n",
    "    item_values = np.hstack((item_values, df.iloc[i][0]))\n",
    "item_values = np.unique(item_values).astype(int)\n",
    "print(item_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_col, rmap_col = {}, {}\n",
    "idx, _columns = 0, []\n",
    "for val in item_values:\n",
    "    map_col[val] = idx\n",
    "    rmap_col[idx] = val\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              productId\n0     [146, 177, 252, 254, 255, 369, 428, 487, 567, ...\n1                                    [4696, 4700, 6038]\n2     [668, 686, 862, 1474, 1936, 2623, 2795, 3305, ...\n3     [179, 455, 830, 1660, 2179, 2704, 2795, 2961, ...\n4     [955, 1544, 1720, 2137, 2235, 2674, 3282, 3504...\n...                                                 ...\n1927  [1617, 4394, 8055, 16098, 16541, 18388, 18392,...\n1928         [12541, 13960, 17276, 18899, 19183, 20290]\n1929           [308, 14425, 19177, 19658, 20776, 21646]\n1930                                            [15047]\n1931  [6273, 7602, 11365, 12084, 12881, 13777, 15653...\n\n[1932 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    df.iloc[i][0] = [map_col[val] for val in df.iloc[i][0]]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transactionEncoder(df):\n",
    "    # 'transactions' is now temporary variable\n",
    "    transactions = [row[\"productId\"] for index, row in df.iterrows()]\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "    transaction_encoder = TransactionEncoder()\n",
    "    wish_matrix = transaction_encoder.fit_transform(transactions).astype(\"int\")\n",
    "    wish_df = pd.DataFrame(wish_matrix, columns=transaction_encoder.columns_)\n",
    "\n",
    "    return wish_df, wish_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   0      1      2      3      4      5      6      7      8      9      ...  \\\n0      0      0      0      0      0      0      0      0      0      0  ...   \n1      0      0      0      0      0      0      0      0      0      0  ...   \n2      0      0      0      0      0      0      0      0      0      0  ...   \n3      0      0      0      0      0      0      0      0      0      0  ...   \n4      0      0      0      0      0      0      0      0      0      0  ...   \n\n   21644  21645  21646  21647  21648  21649  21650  21651  21652  21653  \n0      0      0      0      0      0      0      0      0      0      0  \n1      0      0      0      0      0      0      0      0      0      0  \n2      0      0      0      0      0      0      0      0      0      0  \n3      0      0      0      0      0      0      0      0      0      0  \n4      0      0      0      0      0      0      0      0      0      0  \n\n[5 rows x 21654 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "wish_df, wish_matrix = transactionEncoder(df)\n",
    "\n",
    "print(wish_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  91,  92,\n        93,  94,  95,  96,  98,  99, 100, 102, 103, 104, 105, 106, 107,\n       109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n       122, 123, 124, 125, 126, 128, 131, 132, 134, 135, 136, 137, 140,\n       141, 142, 143, 144, 145, 146, 148, 149, 151, 153, 154, 158, 160,\n       161, 164, 165, 167, 169, 170, 172, 173, 174, 175, 178, 180, 183,\n       184, 185, 188, 189, 194, 197, 199, 202, 203, 205, 206, 210, 220,\n       228, 231, 232, 233, 240, 246, 248, 254, 299, 322, 347, 348, 356,\n       359, 374, 426]), array([10834,  3464,  1734,  1086,   728,   546,   409,   309,   269,\n         190,   166,   168,   148,   101,   107,    86,    77,    72,\n          51,    53,    57,    54,    38,    26,    38,    48,    28,\n          21,    28,    25,    26,    12,    19,    29,    21,    20,\n          18,    19,    15,    15,    21,    13,    16,     9,     8,\n          10,     9,    12,    10,     7,     8,     7,    12,    11,\n           9,     8,    15,     8,     6,     9,    10,     8,     7,\n           9,     8,     8,     4,     4,     5,     3,     3,     4,\n           2,     4,     5,     4,     6,     5,     2,     6,     3,\n           5,     5,     4,     4,     2,     3,     4,     3,     5,\n           5,     2,     1,     3,     1,     2,     1,     3,     1,\n           1,     1,     2,     3,     1,     1,     3,     3,     1,\n           3,     1,     3,     2,     2,     4,     2,     1,     2,\n           1,     1,     1,     1,     3,     1,     1,     1,     1,\n           1,     2,     2,     1,     1,     2,     2,     1,     2,\n           1,     2,     2,     2,     3,     1,     1,     1,     1,\n           1,     2,     1,     1,     1,     1,     1,     2,     1,\n           1,     2,     1,     2,     3,     1,     1,     1,     1,\n           2,     1,     1,     1,     1,     2,     1,     1,     1,\n           1,     1,     2,     1,     1,     3,     1,     1,     1,\n           1,     1,     1,     1,     1]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(wish_df.sum(), return_counts=True))"
   ]
  },
  {
   "source": [
    "# Transaction-based wish prediction using apriori"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    support itemsets\n0  0.166667   (2877)\n1  0.179607   (4032)\n2  0.185818   (5202)\n3  0.220497   (6441)\n4  0.154762   (6474)\n5  0.184265   (6965)\n6  0.180124   (7080)\n7  0.193582   (8021)\nEmpty DataFrame\nColumns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "frequent_itemsets = apriori(wish_df, min_support=0.15)\n",
    "print(frequent_itemsets)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\")\n",
    "# Something FAILED\n",
    "print(rules)"
   ]
  },
  {
   "source": [
    "# Item-based prediction using cosine similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def to_row_df(items, _columns):\n",
    "    row_df = pd.DataFrame(data=[np.zeros(len(_columns)).astype(int)], columns=_columns)\n",
    "    for i in items:\n",
    "        row_df[i] = 1\n",
    "    return row_df\n",
    "\n",
    "def predict (row_df, train_df, test_items, return_num=5):\n",
    "    sim_items = cosine_similarity(row_df, train_df[:])[0]\n",
    "    \n",
    "    for j in test_items:\n",
    "        tu = mau = 0\n",
    "        for i in range(train_df.shape[0]):\n",
    "            tu += sim_items[i] * train_df.iloc[i][j]\n",
    "            mau += sim_items[i]\n",
    "        pred = tu/mau\n",
    "        print(pred)\n",
    "        if pred > 0:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def predict_item_based (row_df, train_df, test_items, return_num=5):\n",
    "    for j in test_items:\n",
    "        sim_items = cosine_similarity([train_df[:][j]], train_df[:].T)[0]\n",
    "        tu = mau = 0\n",
    "        for i in range(len(train_df.columns)):\n",
    "            val = train_df.columns[i]\n",
    "            if val != j:\n",
    "                tu += sim_items[i] * row_df[val].values[0]\n",
    "                mau += sim_items[i]\n",
    "        pred = tu/mau\n",
    "        print(pred)\n",
    "        if pred > 0.002:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1352\n580\n"
     ]
    }
   ],
   "source": [
    "pivot = int(0.7*len(df))\n",
    "# print(pivot)\n",
    "train_set = df[:pivot]\n",
    "test_set  = df[pivot:]\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0025326969486881156\n",
      "1/2 - score = 1 - time = 1.386591911315918\n",
      "0.00023690366568479012\n",
      "2/4 - score = 1 - time = 1.1169862747192383\n",
      "0.000415140264605598\n",
      "3/8 - score = 1 - time = 0.9007430076599121\n",
      "0.00181739090809337\n",
      "4/9 - score = 1 - time = 1.154278039932251\n",
      "0.002632058034792406\n",
      "5/11 - score = 2 - time = 1.1360828876495361\n",
      "0.0004081923537628593\n",
      "6/14 - score = 2 - time = 1.1274189949035645\n",
      "0.0005033281170153048\n",
      "7/15 - score = 2 - time = 1.1165060997009277\n",
      "0.006468817355461303\n",
      "8/20 - score = 3 - time = 0.9073388576507568\n",
      "0.00604581844694567\n",
      "9/22 - score = 4 - time = 0.9018759727478027\n",
      "0.0030946495834271942\n",
      "10/25 - score = 5 - time = 1.1424288749694824\n",
      "0.005103691631053994\n",
      "11/26 - score = 6 - time = 1.1430199146270752\n",
      "0.0019783260628917156\n",
      "12/28 - score = 6 - time = 1.1247320175170898\n",
      "0.001376086698460564\n",
      "13/30 - score = 6 - time = 1.1337170600891113\n",
      "0.004294514603089842\n",
      "14/31 - score = 7 - time = 0.9132001399993896\n",
      "0.0020757632896935834\n",
      "15/32 - score = 8 - time = 0.9081740379333496\n",
      "0.000142732348997012\n",
      "16/33 - score = 8 - time = 1.1269030570983887\n",
      "0.0013072863934864112\n",
      "17/34 - score = 8 - time = 1.1421279907226562\n",
      "0.001959561799467001\n",
      "18/36 - score = 8 - time = 1.1572809219360352\n",
      "0.00041175644987540634\n",
      "19/38 - score = 8 - time = 1.125108003616333\n",
      "0.009973174740801722\n",
      "20/40 - score = 9 - time = 1.3193137645721436\n",
      "58.06402778625488\n",
      "cnt = 20\n",
      "score = 9\n"
     ]
    }
   ],
   "source": [
    "def in_train_lst(lst, _columns):\n",
    "    for j in lst:\n",
    "        if j not in _columns:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def givenN_evaluate(train, test, given_num):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    train_df, train_matrix = transactionEncoder(train)\n",
    "    score = cnt = 0\n",
    "    for i in range(len(test)):\n",
    "        lst = test.iloc[i][0]\n",
    "        if len(lst) <= given_num or not in_train_lst(lst, train_df.columns):\n",
    "            continue\n",
    "        given_items = lst[:-given_num]\n",
    "        test_items = lst[-given_num:]\n",
    "        # print(test_items, train_df.columns)\n",
    "        row_df = to_row_df(given_items, train_df.columns)\n",
    "        _start_time = time.time()\n",
    "        score += predict_item_based(row_df, train_df, test_items, 10)\n",
    "        # break\n",
    "        cnt += 1\n",
    "        print(\"{}/{} - score = {} - time = {}\".format(cnt, i+1, score, time.time() - _start_time))\n",
    "        if cnt == 20:\n",
    "            break\n",
    "    print(time.time() - start_time)\n",
    "    print('cnt =', cnt)\n",
    "    return score\n",
    "\n",
    "score = givenN_evaluate(train_set, test_set, 1) #given 1\n",
    "print('score =', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}